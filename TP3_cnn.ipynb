{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Universidad Torcuato Di Tella\n",
        "\n",
        "Licenciatura en Tecnología Digital\\\n",
        "**Tecnología Digital VI: Inteligencia Artificial**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import tarfile\n",
        "import wandb\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchaudio.datasets import GTZAN\n",
        "from torch.utils.data import DataLoader\n",
        "import torchaudio.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# TP3: Encodeador de música\n",
        "\n",
        "\n",
        "\n",
        "## Orden de pasos\n",
        "\n",
        "0. Elijan GPU para que corra mas rapido (RAM --> change runtime type --> T4 GPU)\n",
        "1. Descargamos el dataset y lo descomprimimos en alguna carpeta en nuestro drive.\n",
        "2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
        "3. Visualización de los archivos\n",
        "4. Clasificación\n",
        "5. Evaluación\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_name='TP3-TD6'\n",
        "username = \"sansonmariano-universidad-torcuato-di-tella\"\n",
        "wandb.login(key=\"d2875c91a36209496ee81454cccd95ebe3dc948d\")\n",
        "wandb.init(project = project_name, entity = username)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_seed = 42\n",
        "\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# Definir parámetros\n",
        "samplerate = 22050\n",
        "data_dir = './genres_5sec'\n",
        "\n",
        "init_batch_size = 20\n",
        "init_num_epochs = 10\n",
        "init_lr = 0.0005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función para parsear géneros\n",
        "def parse_genres(fname):\n",
        "    parts = fname.split('/')[-1].split('.')[0]\n",
        "    return parts\n",
        "\n",
        "# Definir la clase del dataset\n",
        "class MusicDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.files = []\n",
        "        for c in os.listdir(root):\n",
        "            self.files += [os.path.join(root, c, fname) for fname in os.listdir(os.path.join(root, c)) if fname.endswith('.wav')]\n",
        "        self.classes = list(set(parse_genres(fname) for fname in self.files))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fpath = self.files[idx]\n",
        "        genre = parse_genres(fpath)\n",
        "        class_idx = self.classes.index(genre)\n",
        "        audio = torchaudio.load(fpath)[0]\n",
        "        return audio, class_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Cargar el dataset\n",
        "dataset = MusicDataset(data_dir)\n",
        "\n",
        "# Ensure labels match the number of samples\n",
        "# Adjust if 'targets' is not the correct attribute\n",
        "labels = dataset.classes if hasattr(dataset, 'targets') else [dataset[i][1] for i in range(len(dataset))]\n",
        "\n",
        "# Initialize StratifiedShuffleSplit\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "\n",
        "# First, split into training (70%) and temp (30% for val + test)\n",
        "for train_idx, temp_idx in split.split(range(len(dataset)), labels):\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    temp_dataset = Subset(dataset, temp_idx)\n",
        "\n",
        "# Next, split the temp dataset (30%) into validation (15%) and test (15%)\n",
        "val_test_labels = [labels[i] for i in temp_idx]\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
        "for val_idx, test_idx in split.split(temp_idx, val_test_labels):\n",
        "    val_dataset = Subset(dataset, [temp_idx[i] for i in val_idx])\n",
        "    test_dataset = Subset(dataset, [temp_idx[i] for i in test_idx])\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=init_batch_size, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=init_batch_size, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=init_batch_size, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_files=os.listdir(data_dir)\n",
        "\n",
        "classes = []\n",
        "\n",
        "for file in list_files:\n",
        "\n",
        "  name='{}/{}'.format(data_dir,file)\n",
        "\n",
        "  if os.path.isdir(name):\n",
        "\n",
        "    classes.append(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Visualización de los archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def audio_to_spectrogram(waveform):\n",
        "    # Ensure the waveform is in the correct shape\n",
        "    if len(waveform.shape) == 1:\n",
        "        waveform = waveform.unsqueeze(0)\n",
        "    \n",
        "    # Convert the waveform to a spectrogram\n",
        "    spectrogram = tt.Spectrogram()(waveform)\n",
        "    return spectrogram\n",
        "\n",
        "def process_dataloader_to_spectrograms(dataloader):\n",
        "    spectrograms = []\n",
        "    \n",
        "    for batch in dataloader:\n",
        "        # Assuming the batch is a tuple (waveforms, labels) and waveforms are the audio data\n",
        "        waveforms, labels = batch\n",
        "        \n",
        "        # Process each waveform in the batch\n",
        "        batch_spectrograms = [audio_to_spectrogram(waveform) for waveform in waveforms]\n",
        "        \n",
        "        # Append to the list of spectrograms\n",
        "        spectrograms.append((torch.stack(batch_spectrograms), labels))\n",
        "    \n",
        "    return spectrograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_channels = 1  # for RGB images, or 1 for grayscale\n",
        "num_classes = 10    # depends on your specific classification task\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_spectogram = process_dataloader_to_spectrograms(train_loader)\n",
        "val_spectogram = process_dataloader_to_spectrograms(val_loader)\n",
        "test_spectogram = process_dataloader_to_spectrograms(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ejercicio 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modelo que recibe el tamaño de la capa y la cantidad de capas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ajuste en la clase del modelo\n",
        "class ExperimentNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, layer_size, layers):\n",
        "        super(ExperimentNN, self).__init__()\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        self.dropout = nn.Dropout(p=0.5)  # Dropout layer with 50% probability\n",
        "\n",
        "        for layer in range(layers - 1):\n",
        "            if layer == 0:\n",
        "                self.fc_layers.append(nn.Linear(input_size, layer_size))\n",
        "            else:\n",
        "                self.fc_layers.append(nn.Linear(layer_size, layer_size))\n",
        "        \n",
        "        # Output layer\n",
        "        self.fc_layers.append(nn.Linear(layer_size, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Aplanar la onda de audio\n",
        "        x = (x - x.mean()) / x.std()  # Normalización\n",
        "        for fc in self.fc_layers[:-1]:  # Skip last layer\n",
        "            x = self.dropout(F.relu(fc(x)))  # ReLU + Dropout\n",
        "        x = self.fc_layers[-1](x)  # Output layer (no activation)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, epochs, train_loader, val_loader, device):\n",
        "    best_loss = float(\"inf\")\n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Train loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "        val_loss /= len(val_loader)\n",
        "        print(f\"Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            print(f\"New best validation loss: {best_loss:.4f}\")\n",
        "\n",
        "        # Update learning rate with scheduler\n",
        "        scheduler.step(val_loss)\n",
        "        \n",
        "        # Clear cache and collect garbage\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return best_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_size = samplerate * 5\n",
        "\n",
        "num_classes = len(dataset.classes)  # Número de clases (géneros musicales)\n",
        "\n",
        "# Define nuevos valores de hiperparámetros para experimentar\n",
        "layers_list = [2, 3, 5, 7]       # Pruebas con más capas\n",
        "sizes_list = [32, 64, 128, 256]  # Pruebas con más unidades en cada capa\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "best_val_accuracy = 0\n",
        "learning_rate = 0.0005\n",
        "weight_decay = 1e-4\n",
        "best_model = None\n",
        "\n",
        "# Loop de experimentación\n",
        "for layers in layers_list:\n",
        "    for size in sizes_list:\n",
        "        print(f\"Experimentando con {layers} capas y {size} unidades por capa...\")\n",
        "        \n",
        "        # Inicializar el modelo con la configuración actual\n",
        "        model = ExperimentNN(input_size,\n",
        "                             num_classes,\n",
        "                             size,\n",
        "                             layers).to(device)\n",
        "\n",
        "        # Definir el criterio y optimizador con los pesos de las clases\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "        # Define el scheduler\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "        # Llama a train_model pasándole el scheduler\n",
        "        validation_loss = train_model(\n",
        "            model, criterion, optimizer, scheduler=scheduler, epochs=10,\n",
        "            train_loader=train_loader, val_loader=val_loader, device=device\n",
        "        )\n",
        "\n",
        "        # Calcular precisión de validación\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = len(val_loader.dataset)\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                predicted = outputs.argmax(dim=1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        val_accuracy = 100 * correct / total\n",
        "\n",
        "        print(f\"Loss de validación para {layers} capas y {size} unidades: {validation_loss}\")\n",
        "        print(f\"Precisión de validación: {val_accuracy:.2f}%\")\n",
        "\n",
        "        # Guardar el modelo con mejor precisión y menor pérdida\n",
        "        if val_accuracy > best_val_accuracy or (val_accuracy == best_val_accuracy and validation_loss < best_val_loss):\n",
        "            best_val_loss = validation_loss\n",
        "            best_val_accuracy = val_accuracy\n",
        "            best_model = model\n",
        "            print(f\"Nuevo mejor modelo encontrado con {layers} capas y {size} unidades.\")\n",
        "\n",
        "print(f\"Mejor modelo: {layers} capas y {size} unidades, con precisión de validación de {best_val_accuracy:.2f}% y pérdida de validación de {best_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluación final en el conjunto de prueba\n",
        "print(\"Evaluando el mejor modelo en el conjunto de prueba...\")\n",
        "best_model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = len(test_loader.dataset)\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = best_model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        predicted = outputs.argmax(dim=1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = 100 * correct / total\n",
        "\n",
        "print(f\"Loss en el conjunto de prueba: {test_loss:.4f}\")\n",
        "print(f\"Precisión en el conjunto de prueba: {test_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Clasificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes, conv_layers_config):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Initialize the list to hold the convolutional layers\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "\n",
        "        # Initialize the number of input channels for the first layer\n",
        "        in_channels = input_channels\n",
        "\n",
        "        # Dynamically create convolutional layers based on the configuration\n",
        "        for (out_channels, kernel_size, stride, padding) in conv_layers_config:\n",
        "            self.conv_layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding))\n",
        "            in_channels = out_channels  # Update in_channels for the next layer\n",
        "\n",
        "        # Calculate the size after convolution and pooling to define the fully connected layer\n",
        "        # Assuming pooling reduces the size by a factor of 2 at each layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Get the final feature map size (after all conv and pooling layers)\n",
        "        self.final_feature_map_size = self._get_conv_output_size(input_channels, conv_layers_config)\n",
        "        \n",
        "        # Define 9 fully connected layers with 256 nodes each\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        self.fc_layers.append(nn.Linear(self.final_feature_map_size, 256))  # First fully connected layer\n",
        "        for _ in range(8):  # Add 8 more fully connected layers with 256 nodes\n",
        "            self.fc_layers.append(nn.Linear(256, 256))\n",
        "        \n",
        "        # Output layer\n",
        "        self.fc_out = nn.Linear(256, num_classes)  # Output layer for classification\n",
        "        \n",
        "    def _get_conv_output_size(self, input_channels, conv_layers_config):\n",
        "        # Sample input size (height x width) to calculate the final feature map size\n",
        "        # You can adjust these values based on your actual input size\n",
        "        height = 201  # Replace with your actual input height\n",
        "        width = 552   # Replace with your actual input width\n",
        "        \n",
        "        # Apply each convolutional and pooling layer\n",
        "        for (out_channels, kernel_size, stride, padding) in conv_layers_config:\n",
        "            height = (height + 2 * padding - kernel_size) // stride + 1\n",
        "            width = (width + 2 * padding - kernel_size) // stride + 1\n",
        "            height = height // 2  # Max pooling halves the height\n",
        "            width = width // 2    # Max pooling halves the width\n",
        "        \n",
        "        # Return the total number of features after all convolutional and pooling layers\n",
        "        return out_channels * height * width\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply each convolutional layer followed by ReLU and pooling\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = F.relu(conv_layer(x))\n",
        "            x = self.pool(x)\n",
        "        \n",
        "        # Flatten the output before passing it to the fully connected layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the feature map\n",
        "\n",
        "        # Apply the fully connected layers\n",
        "        for fc in self.fc_layers:\n",
        "            x = F.relu(fc(x))\n",
        "        \n",
        "        # Output layer (classification)\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10, device=\"cpu\"):\n",
        "\n",
        "    model.train()  # Set the model to training mode\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        print(f\"\\nStarting Epoch {epoch+1}/{num_epochs}\")\n",
        "        \n",
        "        # Training loop\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Accumulate loss\n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            # Print loss for every batch\n",
        "            if (i + 1) % 10 == 0 or (i + 1) == len(train_loader):\n",
        "                print(f\"  Batch {i+1}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
        "        \n",
        "        # Average loss for the epoch\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1} Training completed. Average Loss: {avg_train_loss:.4f}\")\n",
        "        \n",
        "    print(\"\\nTraining complete.\")\n",
        "\n",
        "def test_model_configuration(model, test_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test set.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0  # Total number of samples processed\n",
        "\n",
        "    # Ensure no gradient computation during evaluation\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:  # Assuming test_loader is the correct DataLoader for your test set\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Get the predicted class labels (the one with the highest logit)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Accumulate total samples\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Accumulate correct predictions\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average test loss\n",
        "    test_loss /= len(test_loader)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    return test_loss, accuracy\n",
        "\n",
        "def test_multiple_configurations(train_loader, test_loader, criterion, device, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Test multiple model configurations and evaluate their performance after training.\n",
        "    \"\"\"\n",
        "    # Different configurations for the CNN model\n",
        "    configurations = [\n",
        "        # Example of convolutional layers configuration (out_channels, kernel_size, stride, padding)\n",
        "        [(32, 3, 1, 1), (64, 3, 1, 1), (128, 3, 1, 1)],  # Configuration 1\n",
        "        [(32, 5, 1, 2), (64, 5, 1, 2)],                   # Configuration 2\n",
        "        [(16, 3, 1, 1), (32, 3, 1, 1), (64, 3, 1, 1)],   # Configuration 3\n",
        "        [(64, 3, 1, 1), (128, 3, 1, 1), (256, 3, 1, 1)]  # Configuration 4\n",
        "    ]\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "    \n",
        "    for idx, conv_layers_config in enumerate(configurations):\n",
        "        print(f\"\\nTesting Configuration {idx + 1} with convolutional layers: {conv_layers_config}\")\n",
        "        \n",
        "        # Initialize the model with the current configuration\n",
        "        model = CNN(input_channels=1, num_classes=10, conv_layers_config=conv_layers_config)\n",
        "        model.to(device)  # Send the model to the appropriate device (GPU/CPU)\n",
        "        \n",
        "        # Initialize optimizer (e.g., Adam) and train the model\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        \n",
        "        # Train the model on the training set\n",
        "        train_model(model, train_loader, criterion, optimizer, num_epochs, device)\n",
        "        \n",
        "        # Evaluate the model on the test set\n",
        "        test_loss, accuracy = test_model_configuration(model, test_loader, criterion, device)\n",
        "\n",
        "        # Print the results for the current configuration\n",
        "        print(f\"Configuration {idx + 1} Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
        "        \n",
        "        # Save the best model based on accuracy\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "\n",
        "    print(f\"\\nBest Model Test Accuracy: {best_accuracy:.2f}%\")\n",
        "    return best_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assume 'test_loader' is the DataLoader for your test set, and 'criterion' is the loss function (e.g., CrossEntropyLoss)\n",
        "best_model = test_multiple_configurations(train_spectogram, val_spectogram, criterion, device, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, accuracy = test_model_configuration(best_model, test_spectogram,criterion,device)\n",
        "\n",
        "print(f\"Loss: {test_loss} - Accuracy: {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "TD6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
