{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Universidad Torcuato Di Tella\n",
        "\n",
        "Licenciatura en Tecnología Digital\\\n",
        "**Tecnología Digital VI: Inteligencia Artificial**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import tarfile\n",
        "import wandb\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchaudio.datasets import GTZAN\n",
        "from torch.utils.data import DataLoader\n",
        "import torchaudio.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# TP3: Encodeador de música\n",
        "\n",
        "\n",
        "\n",
        "## Orden de pasos\n",
        "\n",
        "0. Elijan GPU para que corra mas rapido (RAM --> change runtime type --> T4 GPU)\n",
        "1. Descargamos el dataset y lo descomprimimos en alguna carpeta en nuestro drive.\n",
        "2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
        "3. Visualización de los archivos\n",
        "4. Clasificación\n",
        "5. Evaluación\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_name='TP3-TD6'\n",
        "username = \"sansonmariano-universidad-torcuato-di-tella\"\n",
        "wandb.login(key=\"d2875c91a36209496ee81454cccd95ebe3dc948d\")\n",
        "wandb.init(project = project_name, entity = username)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_seed = 42\n",
        "\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# Definir parámetros\n",
        "samplerate = 22050\n",
        "data_dir = './genres_5sec'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función para parsear géneros\n",
        "def parse_genres(fname):\n",
        "    parts = fname.split('/')[-1].split('.')[0]\n",
        "    return parts\n",
        "\n",
        "# Definir la clase del dataset\n",
        "class MusicDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.files = []\n",
        "        for c in os.listdir(root):\n",
        "            self.files += [os.path.join(root, c, fname) for fname in os.listdir(os.path.join(root, c)) if fname.endswith('.wav')]\n",
        "        self.classes = list(set(parse_genres(fname) for fname in self.files))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fpath = self.files[idx]\n",
        "        genre = parse_genres(fpath)\n",
        "        class_idx = self.classes.index(genre)\n",
        "        audio = torchaudio.load(fpath)[0]\n",
        "        return audio, class_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torch\n",
        "\n",
        "def calculate_mean_std(dataset):\n",
        "    \"\"\"\n",
        "    Calculate mean and standard deviation of the audio data in the dataset.\n",
        "    \"\"\"\n",
        "    all_data = []\n",
        "    for i in range(len(dataset)):\n",
        "        audio, _ = dataset[i]\n",
        "        all_data.append(audio)\n",
        "    stacked_data = torch.cat(all_data, dim=1)\n",
        "    mean = stacked_data.mean()\n",
        "    std = stacked_data.std()\n",
        "    return mean, std\n",
        "\n",
        "def normalize_dataset(dataset, mean, std):\n",
        "    \"\"\"\n",
        "    Normalize the dataset using provided mean and standard deviation.\n",
        "    \"\"\"\n",
        "    normalized_data = []\n",
        "    for i in range(len(dataset)):\n",
        "        audio, label = dataset[i]\n",
        "        normalized_audio = (audio - mean) / std\n",
        "        normalized_data.append((normalized_audio, label))\n",
        "    return normalized_data\n",
        "\n",
        "def create_dataloaders(dataset, batch_size, test_size=0.3, val_size=0.5, random_state=42):\n",
        "    \"\"\"\n",
        "    Splits the dataset into train, validation, and test subsets, normalizes them,\n",
        "    and returns corresponding DataLoaders.\n",
        "    \"\"\"\n",
        "    # Stratified split: train and temporary (val+test) split\n",
        "    labels = [label for _, label in dataset]\n",
        "    split = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
        "    for train_idx, temp_idx in split.split(range(len(dataset)), labels):\n",
        "        train_dataset = Subset(dataset, train_idx)\n",
        "        temp_dataset = Subset(dataset, temp_idx)\n",
        "\n",
        "    # Calculate mean and std on the training set only\n",
        "    mean, std = calculate_mean_std(train_dataset)\n",
        "\n",
        "    # Normalize each subset\n",
        "    train_dataset = normalize_dataset(train_dataset, mean, std)\n",
        "    temp_dataset = normalize_dataset(temp_dataset, mean, std)\n",
        "\n",
        "    # Stratified split on temp data: validation and test split\n",
        "    val_test_labels = [labels[i] for i in temp_idx]\n",
        "    split = StratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=random_state)\n",
        "    for val_idx, test_idx in split.split(temp_idx, val_test_labels):\n",
        "        val_dataset = Subset(temp_dataset, val_idx)\n",
        "        test_dataset = Subset(temp_dataset, test_idx)\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    return train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset\n",
        "\n",
        "# Usage example with MusicDataset\n",
        "dataset = MusicDataset(data_dir)\n",
        "batch_size = 20\n",
        "train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset = create_dataloaders(dataset, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_files=os.listdir(data_dir)\n",
        "\n",
        "classes = []\n",
        "\n",
        "for file in list_files:\n",
        "\n",
        "  name='{}/{}'.format(data_dir,file)\n",
        "\n",
        "  if os.path.isdir(name):\n",
        "\n",
        "    classes.append(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Visualización de los archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def audio_to_spectrogram(waveform):\n",
        "    # Ensure the waveform is in the correct shape\n",
        "    if len(waveform.shape) == 1:\n",
        "        waveform = waveform.unsqueeze(0)\n",
        "    \n",
        "    # Convert the waveform to a spectrogram\n",
        "    spectrogram = tt.Spectrogram()(waveform)\n",
        "    return spectrogram\n",
        "\n",
        "def process_dataloader_to_spectrograms(dataloader):\n",
        "    spectrograms = []\n",
        "    \n",
        "    for batch in dataloader:\n",
        "        # Assuming the batch is a tuple (waveforms, labels) and waveforms are the audio data\n",
        "        waveforms, labels = batch\n",
        "        \n",
        "        # Process each waveform in the batch\n",
        "        batch_spectrograms = [audio_to_spectrogram(waveform) for waveform in waveforms]\n",
        "        \n",
        "        # Append to the list of spectrograms\n",
        "        spectrograms.append((torch.stack(batch_spectrograms), labels))\n",
        "    \n",
        "    return spectrograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_channels = 1  # for RGB images, or 1 for grayscale\n",
        "num_classes = 10    # depends on your specific classification task\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_spectogram = process_dataloader_to_spectrograms(train_loader)\n",
        "val_spectogram = process_dataloader_to_spectrograms(val_loader)\n",
        "test_spectogram = process_dataloader_to_spectrograms(test_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ejercicio 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modelo que recibe el tamaño de la capa y la cantidad de capas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ajuste en la clase del modelo\n",
        "class ExperimentNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, layer_size, layers):\n",
        "        super(ExperimentNN, self).__init__()\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        self.dropout = nn.Dropout(p=0.5)  # Dropout layer with 50% probability\n",
        "\n",
        "        for layer in range(layers - 1):\n",
        "            if layer == 0:\n",
        "                self.fc_layers.append(nn.Linear(input_size, layer_size))\n",
        "            else:\n",
        "                self.fc_layers.append(nn.Linear(layer_size, layer_size))\n",
        "        \n",
        "        # Output layer\n",
        "        self.fc_layers.append(nn.Linear(layer_size, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Aplanar la onda de audio\n",
        "        x = (x - x.mean()) / x.std()  # Normalización\n",
        "        for fc in self.fc_layers[:-1]:  # Skip last layer\n",
        "            x = self.dropout(F.relu(fc(x)))  # ReLU + Dropout\n",
        "        x = self.fc_layers[-1](x)  # Output layer (no activation)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "def train_model_architecture(model, criterion, optimizer, epochs, train_loader, val_loader, device):\n",
        "    \n",
        "    model_name = f\"{len(model.fc_layers)} capas de {model.fc_layers[0].out_features} nodos\"\n",
        "    \n",
        "    wandb.init(\n",
        "        name = model_name,\n",
        "        config = {\n",
        "            \"learning_rate\": 0.0005,\n",
        "            \"epochs\": epochs,\n",
        "            \"model\": model,\n",
        "        })\n",
        "            \n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Train loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                predicted = outputs.argmax(dim=1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                val_loss += loss.item()\n",
        "        \n",
        "            val_loss /= len(val_loader)\n",
        "        val_accuracy = 100 * (correct / len(val_dataset))\n",
        "        print(f\"\\nValidation loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}%\")\n",
        "        \n",
        "        wandb.log({\"val_loss\": val_loss,\n",
        "                \"val_accuracy\": val_accuracy,\n",
        "                \"train_loss\": train_loss,\n",
        "                \"epoch\": epoch})\n",
        "\n",
        "        # Clear cache and collect garbage\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    wandb.finish()\n",
        "    return val_loss, val_accuracy # Return the final best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_size = samplerate * 5\n",
        "\n",
        "num_classes = len(dataset.classes)  # Número de clases (géneros musicales)\n",
        "\n",
        "# Define nuevos valores de hiperparámetros para experimentar\n",
        "layers_list = [2, 3, 5, 7]       # Pruebas con más capas\n",
        "sizes_list = [32, 64, 128, 256]  # Pruebas con más unidades en cada capa\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "best_val_accuracy = 0\n",
        "learning_rate = 0.0005\n",
        "weight_decay = 1e-4\n",
        "best_model = None\n",
        "\n",
        "# Loop de experimentación\n",
        "for layers in layers_list:\n",
        "    for size in sizes_list:\n",
        "        print(f\"Experimentando con {layers} capas y {size} unidades por capa...\")\n",
        "        \n",
        "        # Inicializar el modelo con la configuración actual\n",
        "        model = ExperimentNN(input_size,\n",
        "                             num_classes,\n",
        "                             size,\n",
        "                             layers).to(device)\n",
        "\n",
        "        # Definir el criterio y optimizador con los pesos de las clases\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "        # Define el scheduler\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "        # Llama a train_model pasándole el scheduler\n",
        "        validation_loss, validation_accuracy = train_model_architecture(\n",
        "            model, criterion, optimizer, epochs=30,\n",
        "            train_loader=train_loader, val_loader=val_loader, device=device\n",
        "        )\n",
        "\n",
        "        print(f\"Loss de validación para {layers} capas y {size} unidades: {validation_loss}\")\n",
        "        print(f\"Precisión de validación: {validation_accuracy:.2f}%\")\n",
        "\n",
        "        # Guardar el modelo con mejor precisión y menor pérdida\n",
        "        if validation_accuracy > best_val_accuracy or (validation_accuracy == best_val_accuracy and validation_loss < best_val_loss):\n",
        "            best_val_loss = validation_loss\n",
        "            best_val_accuracy = validation_accuracy\n",
        "            best_model = model  # Store the model with the best configuration\n",
        "            print(f\"Nuevo mejor modelo encontrado con {layers} capas y {size} unidades.\")\n",
        "\n",
        "print(f\"Mejor modelo: {len(best_model.fc_layers)} capas y {best_model.fc_layers[0].out_features} unidades, con precisión de validación de {best_val_accuracy:.2f}% y pérdida de validación de {best_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluación final en el conjunto de prueba\n",
        "print(\"Evaluando el mejor modelo en el conjunto de prueba...\")\n",
        "best_model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = len(test_dataset.dataset)\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = best_model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        predicted = outputs.argmax(dim=1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_dataset)\n",
        "test_accuracy = 100 * correct / total\n",
        "\n",
        "print(f\"Loss en el conjunto de prueba: {test_loss:.4f}\")\n",
        "print(f\"Precisión en el conjunto de prueba: {test_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Clasificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes, conv_layers_config):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Initialize the list to hold the convolutional layers\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "\n",
        "        # Initialize the number of input channels for the first layer\n",
        "        in_channels = input_channels\n",
        "\n",
        "        # Dynamically create convolutional layers based on the configuration\n",
        "        for (out_channels, kernel_size, stride, padding) in conv_layers_config:\n",
        "            self.conv_layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding))\n",
        "            in_channels = out_channels  # Update in_channels for the next layer\n",
        "\n",
        "        # Calculate the size after convolution and pooling to define the fully connected layer\n",
        "        # Assuming pooling reduces the size by a factor of 2 at each layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Get the final feature map size (after all conv and pooling layers)\n",
        "        self.final_feature_map_size = self._get_conv_output_size(conv_layers_config)\n",
        "        \n",
        "        # Define 9 fully connected layers with 256 nodes each\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        self.fc_layers.append(nn.Linear(self.final_feature_map_size, 256))  # First fully connected layer\n",
        "        for _ in range(4):  # Add 2 more fully connected layers with 256 nodes\n",
        "            self.fc_layers.append(nn.Linear(256, 256))\n",
        "        \n",
        "        # Output layer\n",
        "        self.fc_out = nn.Linear(256, num_classes)  # Output layer for classification\n",
        "        \n",
        "    def _get_conv_output_size(self, conv_layers_config):\n",
        "        # Sample input size (height x width) to calculate the final feature map size\n",
        "        # You can adjust these values based on your actual input size\n",
        "        height = 201  # Replace with your actual input height\n",
        "        width = 552   # Replace with your actual input width\n",
        "        \n",
        "        # Apply each convolutional and pooling layer\n",
        "        for (out_channels, kernel_size, stride, padding) in conv_layers_config:\n",
        "            height = (height + 2 * padding - kernel_size) // stride + 1\n",
        "            width = (width + 2 * padding - kernel_size) // stride + 1\n",
        "            height = height // 2  # Max pooling halves the height\n",
        "            width = width // 2    # Max pooling halves the width\n",
        "        \n",
        "        # Return the total number of features after all convolutional and pooling layers\n",
        "        return out_channels * height * width\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply each convolutional layer followed by ReLU and pooling\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = F.relu(conv_layer(x))\n",
        "            x = self.pool(x)\n",
        "        \n",
        "        # Flatten the output before passing it to the fully connected layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the feature map\n",
        "\n",
        "        # Apply the fully connected layers\n",
        "        for fc in self.fc_layers:\n",
        "            x = F.relu(fc(x))\n",
        "        \n",
        "        # Output layer (classification)\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "def train_model_convolutional(model, criterion, optimizer, epochs, train_loader, val_loader, device, model_number):\n",
        "    \n",
        "    model_name = f\"Test convolucional {model_number}\"\n",
        "    \n",
        "    wandb.init(\n",
        "        name = model_name,\n",
        "        config = {\n",
        "            \"learning_rate\": 0.0005,\n",
        "            \"epochs\": epochs,\n",
        "            \"model\": model,\n",
        "        })\n",
        "            \n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            train_loss /= len(train_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Train loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                predicted = outputs.argmax(dim=1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                val_loss /= len(val_loader)\n",
        "\n",
        "        val_accuracy = 100 * (correct / len(val_dataset))\n",
        "        print(f\"\\nValidation loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}%\")\n",
        "        \n",
        "        wandb.log({\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_accuracy\": val_accuracy,\n",
        "                \"train_loss\": train_loss,\n",
        "                \"epoch\": epoch})\n",
        "\n",
        "        # Clear cache and collect garbage\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    wandb.finish()\n",
        "    return val_loss, val_accuracy # Return the final best model\n",
        "\n",
        "def test_multiple_configurations(train, val, test, criterion, device, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Test multiple model configurations, applying the best gradients for evaluation,\n",
        "    and save the best model based on accuracy or validation loss.\n",
        "    \"\"\"\n",
        "    # Different configurations for the CNN model\n",
        "    configurations = [\n",
        "        [(32, 3, 1, 1), (64, 3, 1, 1), (128, 3, 1, 1)],  # Configuration 1\n",
        "        #[(32, 5, 1, 2), (64, 5, 1, 2)],                  # Configuration 2\n",
        "        #[(16, 3, 1, 1), (32, 3, 1, 1), (64, 3, 1, 1)],   # Configuration 3\n",
        "        [(64, 3, 1, 1), (128, 3, 1, 1), (256, 3, 1, 1)]  # Configuration 4\n",
        "    ]\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "    best_loss = float(\"inf\")\n",
        "    \n",
        "    for idx, conv_layers_config in enumerate(configurations):\n",
        "        print(f\"\\nTesting Configuration {idx + 1} with convolutional layers: {conv_layers_config}\")\n",
        "        \n",
        "        # Initialize the model with the current configuration\n",
        "        model = CNN(input_channels=1, num_classes=10, conv_layers_config=conv_layers_config)\n",
        "        model.to(device)\n",
        "        \n",
        "        # Initialize optimizer (e.g., Adam) and train the model\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        \n",
        "        # Train the model on the training set\n",
        "        val_loss, val_accuracy = train_model_convolutional(model, criterion, optimizer, num_epochs, train, val,device,idx + 1)\n",
        "        \n",
        "        # Print the results for the current configuration\n",
        "        print(f\"Configuration {idx + 1} Test Loss: {val_loss:.4f}, Test Accuracy: {val_accuracy:.2f}%\")\n",
        "        \n",
        "        # Save the best model based on accuracy; if accuracy is the same, use loss as the tie-breaker\n",
        "        if val_accuracy > best_accuracy or (val_accuracy == best_accuracy and val_loss < best_loss):\n",
        "            best_accuracy = val_accuracy\n",
        "            best_loss = test_loss\n",
        "            best_model = model\n",
        "            print(f\"New best model found with accuracy: {best_accuracy:.2f}% and loss: {best_loss:.4f}\")\n",
        "\n",
        "    print(f\"\\nBest Model Test Accuracy: {best_accuracy:.2f}% with Loss: {best_loss:.4f}, model: {best_model}\")\n",
        "    return best_loss, best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/20 - Train loss: 11.1216\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Assume 'test_loader' is the DataLoader for your test set, and 'criterion' is the loss function (e.g., CrossEntropyLoss)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtest_multiple_configurations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_spectogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_spectogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_spectogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[18], line 89\u001b[0m, in \u001b[0;36mtest_multiple_configurations\u001b[1;34m(train, val, test, criterion, device, num_epochs)\u001b[0m\n\u001b[0;32m     86\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Train the model on the training set\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_convolutional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Print the results for the current configuration\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfiguration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[18], line 37\u001b[0m, in \u001b[0;36mtrain_model_convolutional\u001b[1;34m(model, criterion, optimizer, epochs, train_loader, val_loader, device, model_number)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m     36\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 37\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     39\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[21], line 51\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# Apply each convolutional layer followed by ReLU and pooling\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conv_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_layers:\n\u001b[1;32m---> 51\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mconv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     52\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# Flatten the output before passing it to the fully connected layers\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# Assume 'test_loader' is the DataLoader for your test set, and 'criterion' is the loss function (e.g., CrossEntropyLoss)\n",
        "best_model = test_multiple_configurations(train_spectogram, val_spectogram, test_spectogram, criterion, device, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Loss: {best_model[0]} - Model: {best_model[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_best_model = best_model[1]\n",
        "\n",
        "# Evaluación final en el conjunto de prueba\n",
        "print(\"Evaluando el mejor modelo en el conjunto de prueba...\")\n",
        "cnn_best_model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = len(test_dataset.dataset)\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_spectogram:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = cnn_best_model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        predicted = outputs.argmax(dim=1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_dataset)\n",
        "test_accuracy = 100 * correct / total\n",
        "\n",
        "print(f\"Loss en el conjunto de prueba: {test_loss:.4f}\")\n",
        "print(f\"Precisión en el conjunto de prueba: {test_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class different_act_CNN(nn.Module):\n",
        "    def __init__(self, input_channels=1, num_classes=10, activation_function=\"relu\"):\n",
        "        super(different_act_CNN, self).__init__()\n",
        "\n",
        "        # Define the convolutional layers (fixed as per example)\n",
        "        self.conv_layers = nn.ModuleList([\n",
        "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),  # Conv layer 1\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),              # Conv layer 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)              # Conv layer 3\n",
        "        ])\n",
        "        \n",
        "        # Max Pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Calculate the output feature size after conv layers and pooling\n",
        "        self.final_feature_map_size = self._get_conv_output_size()\n",
        "\n",
        "        # Define fully connected layers (fixed as per example)\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        self.fc_layers.append(nn.Linear(self.final_feature_map_size, 256))  # First fully connected layer\n",
        "        for _ in range(4):  # Add 2 more fully connected layers with 256 nodes\n",
        "            self.fc_layers.append(nn.Linear(256, 256))\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc_out = nn.Linear(256, num_classes)\n",
        "\n",
        "        # Set activation function\n",
        "        self.activation = self._get_activation_function(activation_function)\n",
        "\n",
        "    def _get_conv_output_size(self):\n",
        "        # Sample input size (height x width)\n",
        "        height, width = 201, 552  # Replace with actual input height and width\n",
        "\n",
        "        # Pass through convolutional and pooling layers to determine final size\n",
        "        for layer in self.conv_layers:\n",
        "            height = (height + 2 * layer.padding[0] - layer.kernel_size[0]) // layer.stride[0] + 1\n",
        "            width = (width + 2 * layer.padding[1] - layer.kernel_size[1]) // layer.stride[1] + 1\n",
        "            height //= 2  # Max pooling halves the height\n",
        "            width //= 2   # Max pooling halves the width\n",
        "\n",
        "        # Output feature map size\n",
        "        return height * width * 128\n",
        "\n",
        "    def _get_activation_function(self, activation_function):\n",
        "        # Map the string to the appropriate activation function\n",
        "        if activation_function == \"relu\":\n",
        "            return F.relu\n",
        "        elif activation_function == \"leaky_relu\":\n",
        "            return F.leaky_relu\n",
        "        elif activation_function == \"tanh\":\n",
        "            return torch.tanh\n",
        "        elif activation_function == \"sigmoid\":\n",
        "            return torch.sigmoid\n",
        "        elif activation_function == \"softmax\":\n",
        "            return F.softmax\n",
        "        elif activation_function == \"elu\":\n",
        "            return F.elu\n",
        "        elif activation_function == \"selu\":\n",
        "            return F.selu\n",
        "        elif activation_function == \"gelu\":\n",
        "            return F.gelu\n",
        "        elif activation_function == \"swish\":\n",
        "            return lambda x: x * torch.sigmoid(x)  # Swish activation: x * sigmoid(x)\n",
        "        elif activation_function == \"hard_sigmoid\":\n",
        "            return F.hardsigmoid\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation function: {activation_function}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through conv layers with the selected activation function and pooling\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = self.activation(conv_layer(x))\n",
        "            x = self.pool(x)\n",
        "        \n",
        "        # Flatten the output from conv layers\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Forward pass through fully connected layers with the selected activation function\n",
        "        for fc_layer in self.fc_layers:\n",
        "            x = self.activation(fc_layer(x))\n",
        "        \n",
        "        # Final output layer\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model_activation(model, criterion, optimizer, epochs, train_loader, val_loader, device, act_name):\n",
        "    \n",
        "    model_name = f\"Test de {act_name}\"\n",
        "    \n",
        "    wandb.init(\n",
        "        name = model_name,\n",
        "        config = {\n",
        "            \"learning_rate\": 0.0005,\n",
        "            \"epochs\": epochs,\n",
        "            \"model\": model,\n",
        "        })\n",
        "            \n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Train loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                predicted = outputs.argmax(dim=1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                val_loss += loss.item()\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "\n",
        "        val_accuracy = 100 * (correct / len(val_dataset))\n",
        "        print(f\"\\nValidation loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}%\")\n",
        "        \n",
        "        wandb.log({\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_accuracy\": val_accuracy,\n",
        "                \"train_loss\": train_loss,\n",
        "                \"epoch\": epoch})\n",
        "\n",
        "        # Clear cache and collect garbage\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    wandb.finish()\n",
        "    return val_loss, val_accuracy # Return the final best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to test different activation functions\n",
        "def test_multiple_activation_functions(train, val, test, criterion, device, num_epochs=10):\n",
        "    #activation_functions = [\"relu\", \"leaky_relu\", \"tanh\", \"sigmoid\", \"softmax\", \"elu\", \"selu\", \"gelu\", \"swish\", \"hard_sigmoid\"]\n",
        "    activation_functions = [\"elu\"]\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "    best_loss = float(\"inf\")\n",
        "    \n",
        "    for activation_function in activation_functions:\n",
        "        print(f\"\\nTesting activation function: {activation_function}\")\n",
        "        \n",
        "        model = different_act_CNN(input_channels=1, num_classes=10, activation_function=activation_function)\n",
        "        model.to(device)\n",
        "        \n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        val_loss, val_accuracy = train_model_activation(model, criterion, optimizer, 20, train, val, device, activation_function)\n",
        "        \n",
        "        \n",
        "        print(f\"Activation function: {activation_function} Test Loss: {val_loss:.4f}, Test Accuracy: {val_accuracy:.2f}%\")\n",
        "        \n",
        "        if val_accuracy > best_accuracy or (val_accuracy == best_accuracy and val_loss < best_loss):\n",
        "            best_accuracy = val_accuracy\n",
        "            best_loss = test_loss\n",
        "            best_model = model\n",
        "            print(f\"New best model found with accuracy: {best_accuracy:.2f}% and loss: {best_loss:.4f}\")\n",
        "\n",
        "    print(f\"\\nBest Model Test Accuracy: {best_accuracy:.2f}% with Loss: {best_loss:.4f}\")\n",
        "    return best_loss, best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing activation function: elu\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:w2ulm1dd) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Test de elu</strong> at: <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/w2ulm1dd' target=\"_blank\">https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/w2ulm1dd</a><br/> View project at: <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6' target=\"_blank\">https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20241108_124711-w2ulm1dd\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:w2ulm1dd). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\45235544\\Documents\\TD 6\\tp3-td6\\wandb\\run-20241108_124807-xetneq19</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/xetneq19' target=\"_blank\">Test de elu</a></strong> to <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6' target=\"_blank\">https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/xetneq19' target=\"_blank\">https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/xetneq19</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 - Train loss: 11.9935\n",
            "\n",
            "Validation loss: 2.0347, Accuracy: 22.2973%\n",
            "Epoch 2/20 - Train loss: 1.9352\n",
            "\n",
            "Validation loss: 1.7954, Accuracy: 31.7568%\n",
            "Epoch 3/20 - Train loss: 1.3312\n",
            "\n",
            "Validation loss: 1.9604, Accuracy: 35.1351%\n",
            "Epoch 4/20 - Train loss: 1.0171\n",
            "\n",
            "Validation loss: 2.1201, Accuracy: 35.8108%\n",
            "Epoch 5/20 - Train loss: 0.6685\n",
            "\n",
            "Validation loss: 2.7892, Accuracy: 40.5405%\n",
            "Epoch 6/20 - Train loss: 0.4226\n",
            "\n",
            "Validation loss: 3.2479, Accuracy: 34.4595%\n",
            "Epoch 7/20 - Train loss: 0.4022\n",
            "\n",
            "Validation loss: 3.3494, Accuracy: 38.5135%\n",
            "Epoch 8/20 - Train loss: 0.3848\n",
            "\n",
            "Validation loss: 4.0193, Accuracy: 34.4595%\n",
            "Epoch 9/20 - Train loss: 0.3797\n",
            "\n",
            "Validation loss: 3.3629, Accuracy: 40.5405%\n",
            "Epoch 10/20 - Train loss: 0.2332\n",
            "\n",
            "Validation loss: 3.0276, Accuracy: 37.8378%\n",
            "Epoch 11/20 - Train loss: 0.3337\n",
            "\n",
            "Validation loss: 2.9943, Accuracy: 38.5135%\n",
            "Epoch 12/20 - Train loss: 0.1332\n",
            "\n",
            "Validation loss: 5.0626, Accuracy: 31.7568%\n",
            "Epoch 13/20 - Train loss: 0.0840\n",
            "\n",
            "Validation loss: 4.7872, Accuracy: 36.4865%\n",
            "Epoch 14/20 - Train loss: 0.2126\n",
            "\n",
            "Validation loss: 5.6110, Accuracy: 34.4595%\n",
            "Epoch 15/20 - Train loss: 0.1879\n",
            "\n",
            "Validation loss: 4.1790, Accuracy: 35.1351%\n",
            "Epoch 16/20 - Train loss: 0.2119\n",
            "\n",
            "Validation loss: 4.0382, Accuracy: 38.5135%\n",
            "Epoch 17/20 - Train loss: 0.0753\n",
            "\n",
            "Validation loss: 3.6077, Accuracy: 42.5676%\n",
            "Epoch 18/20 - Train loss: 0.1299\n",
            "\n",
            "Validation loss: 4.3177, Accuracy: 36.4865%\n",
            "Epoch 19/20 - Train loss: 0.0437\n",
            "\n",
            "Validation loss: 4.5438, Accuracy: 37.8378%\n",
            "Epoch 20/20 - Train loss: 0.0136\n",
            "\n",
            "Validation loss: 5.0891, Accuracy: 38.5135%\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▇▅▇▅▇▆▇▄▆▅▅▇█▆▆▇</td></tr><tr><td>val_loss</td><td>▁▁▁▂▃▄▄▅▄▃▃▇▆█▅▅▄▆▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>train_loss</td><td>0.01361</td></tr><tr><td>val_accuracy</td><td>38.51351</td></tr><tr><td>val_loss</td><td>5.08911</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Test de elu</strong> at: <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/xetneq19' target=\"_blank\">https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/xetneq19</a><br/> View project at: <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6' target=\"_blank\">https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20241108_124807-xetneq19\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activation function: elu Test Loss: 5.0891, Test Accuracy: 38.51%\n",
            "New best model found with accuracy: 38.51% and loss: 0.1220\n",
            "\n",
            "Best Model Test Accuracy: 38.51% with Loss: 0.1220\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Assume 'test_loader' is the DataLoader for your test set, and 'criterion' is the loss function (e.g., CrossEntropyLoss)\n",
        "best_loss, best_model = test_multiple_activation_functions(train_spectogram, val_spectogram, test_spectogram, criterion, device, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluando el mejor modelo en el conjunto de prueba...\n",
            "Loss en el conjunto de prueba: 0.2564\n",
            "Precisión en el conjunto de prueba: 18.86%\n"
          ]
        }
      ],
      "source": [
        "# Evaluación final en el conjunto de prueba\n",
        "print(\"Evaluando el mejor modelo en el conjunto de prueba...\")\n",
        "best_model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = len(test_dataset.dataset)\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_spectogram:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = best_model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        predicted = outputs.argmax(dim=1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_dataset)\n",
        "test_accuracy = 100 * correct / total\n",
        "\n",
        "print(f\"Loss en el conjunto de prueba: {test_loss:.4f}\")\n",
        "print(f\"Precisión en el conjunto de prueba: {test_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DifferentOptCNN(nn.Module):\n",
        "    def __init__(self, optimizer_class, scheduler_fn, learning_rate, scheduler_lr, input_channels=1, num_classes=10):\n",
        "        super(DifferentOptCNN, self).__init__()\n",
        "\n",
        "        # Capas convolucionales con ajustes en kernel_size y stride para evitar reducción excesiva\n",
        "        self.conv_layers = nn.ModuleList([\n",
        "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),  # Conv layer 1\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),              # Conv layer 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)              # Conv layer 3\n",
        "        ])\n",
        "        \n",
        "        # Max Pooling layer con tamaño de kernel ajustado\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Calcular el tamaño final después de las convoluciones\n",
        "        self.final_feature_map_size = self._get_conv_output_size(input_channels)\n",
        "\n",
        "        # Capas densas (sin cambios)\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        self.fc_layers.append(nn.Linear(self.final_feature_map_size, 256))  # First fully connected layer\n",
        "        for _ in range(4):  # Add 2 more fully connected layers with 256 nodes\n",
        "            self.fc_layers.append(nn.Linear(256, 256))\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc_out = nn.Linear(256, num_classes)\n",
        "\n",
        "        # Definir función de activación ELU\n",
        "        self.activation = F.elu\n",
        "\n",
        "        # Configuración del optimizador y scheduler\n",
        "        self.optimizer = optimizer_class(self.parameters(), lr=learning_rate)\n",
        "        self.scheduler = scheduler_fn(self.optimizer, scheduler_lr)\n",
        "\n",
        "    def _get_conv_output_size(self, input_channels):\n",
        "        # Tamaño de entrada (ajustar si es necesario)\n",
        "        height, width = 201, 552  # Reemplaza con el tamaño correcto de entrada si cambió\n",
        "\n",
        "        # Cálculo del tamaño de salida\n",
        "        for layer in self.conv_layers:\n",
        "            height = (height + 2 * layer.padding[0] - layer.kernel_size[0]) // layer.stride[0] + 1\n",
        "            width = (width + 2 * layer.padding[1] - layer.kernel_size[1]) // layer.stride[1] + 1\n",
        "            height //= 2  # Max pooling reduce la altura a la mitad\n",
        "            width //= 2   # Max pooling reduce el ancho a la mitad\n",
        "\n",
        "        return height * width * 128  # Tamaño de la característica de salida final\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pasar por las capas convolucionales con la función de activación ELU y pooling\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = self.activation(conv_layer(x))\n",
        "            x = self.pool(x)\n",
        "        \n",
        "        # Aplanar la salida de las capas convolucionales antes de pasar por las densas\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Pasar por las capas densas con la función de activación ELU\n",
        "        for fc_layer in self.fc_layers:\n",
        "            x = self.activation(fc_layer(x))\n",
        "        \n",
        "        # Capa de salida final\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model_opt_sched_lr(model, criterion, optimizer, epochs, train_loader, val_loader, device, model_name):\n",
        "    \n",
        "    wandb.init(\n",
        "        name = model_name,\n",
        "        config = {\n",
        "            \"learning_rate\": 0.0005,\n",
        "            \"epochs\": epochs,\n",
        "            \"model\": model,\n",
        "        })\n",
        "            \n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Train loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                predicted = outputs.argmax(dim=1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                val_loss += loss.item()\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "\n",
        "        val_accuracy = 100 * (correct / len(val_dataset))\n",
        "        print(f\"\\nValidation loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}%\")\n",
        "        \n",
        "        wandb.log({\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_accuracy\": val_accuracy,\n",
        "                \"train_loss\": train_loss,\n",
        "                \"epoch\": epoch})\n",
        "\n",
        "        # Clear cache and collect garbage\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    wandb.finish()\n",
        "    return val_loss, val_accuracy # Return the final best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR, ExponentialLR, ReduceLROnPlateau\n",
        "import copy\n",
        "\n",
        "def grid_search_model_configurations(train, val, test, criterion, device, num_epochs=10):\n",
        "    # Hiperparámetros a probar\n",
        "    optimizers = {\n",
        "        \"SGD\": optim.SGD,\n",
        "        \"Adam\": optim.Adam,\n",
        "        \"RMSprop\": optim.RMSprop\n",
        "    }\n",
        "    schedulers = {\n",
        "        \"StepLR\": lambda opt, lr: StepLR(opt, step_size=5, gamma=lr),\n",
        "        \"ExponentialLR\": lambda opt, lr: ExponentialLR(opt, gamma=lr),\n",
        "        \"ReduceLROnPlateau\": lambda opt, lr: ReduceLROnPlateau(opt, mode='min', patience=3, factor=lr)\n",
        "    }\n",
        "    learning_rates = [0.001, 0.0005, 0.01]\n",
        "\n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "    best_loss = float(\"inf\")\n",
        "    best_config = {}\n",
        "\n",
        "\n",
        "    for optimizer_name, optimizer_class in optimizers.items():\n",
        "        for scheduler_name, scheduler_fn in schedulers.items():\n",
        "            for lr in learning_rates:\n",
        "                print(f\"\\nTesting config: Optimizer={optimizer_name}, Scheduler={scheduler_name}, Learning Rate={lr}\")\n",
        "\n",
        "                # Inicializar el modelo con la función de activación fija\n",
        "                model = DifferentOptCNN(\n",
        "                    optimizer_class=optimizer_class,\n",
        "                    scheduler_fn=scheduler_fn,\n",
        "                    learning_rate=lr,\n",
        "                    scheduler_lr=lr,\n",
        "                    input_channels=20,  # Ajuste según el tamaño de los datos\n",
        "                    num_classes=10\n",
        "                )\n",
        "                model.to(device)\n",
        "\n",
        "                model_name = f\"Opt: {optimizer_name}, Sch: {scheduler_name}, Lr: {lr}\"\n",
        "\n",
        "                # Entrenar el modelo\n",
        "                val_loss, val_accuracy = train_model_opt_sched_lr(model, criterion, model.optimizer, num_epochs, train, val, device, model_name)\n",
        "\n",
        "                print(f\"Config: Optimizer={optimizer_name}, Scheduler={scheduler_name}, LR={lr} | Test Loss: {test_loss:.4f}, Test Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "                # Guardar el mejor modelo según la precisión y la pérdida en el conjunto de prueba\n",
        "                if val_accuracy > best_accuracy or (val_accuracy == best_accuracy and val_loss < best_loss):\n",
        "                    best_accuracy = val_accuracy\n",
        "                    best_loss = val_loss\n",
        "                    best_model = copy.deepcopy(model)\n",
        "                    best_config = {\n",
        "                        \"optimizer\": optimizer_name,\n",
        "                        \"scheduler\": scheduler_name,\n",
        "                        \"learning_rate\": lr\n",
        "                    }\n",
        "                    print(f\"New best model found with accuracy: {best_accuracy:.2f}% and loss: {best_loss:.4f}\")\n",
        "\n",
        "    print(f\"\\nBest Model Test Accuracy: {best_accuracy:.2f}% with Loss: {best_loss:.4f}\")\n",
        "    print(f\"Best Configuration: {best_config}\")\n",
        "    return best_loss, best_model, best_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing config: Optimizer=SGD, Scheduler=StepLR, Learning Rate=0.001\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:hex3foxs) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Opt: SGD, Sch: StepLR, Lr: 0.001</strong> at: <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/hex3foxs' target=\"_blank\">https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/hex3foxs</a><br/> View project at: <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6' target=\"_blank\">https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20241108_143031-hex3foxs\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:hex3foxs). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\45235544\\Documents\\TD 6\\tp3-td6\\wandb\\run-20241108_143119-8vh94lav</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/8vh94lav' target=\"_blank\">Opt: SGD, Sch: StepLR, Lr: 0.001</a></strong> to <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6' target=\"_blank\">https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/8vh94lav' target=\"_blank\">https://wandb.ai/sansonmariano-universidad-torcuato-di-tella/TP3-TD6/runs/8vh94lav</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "Given input size: (32x1x110250). Calculated output size: (32x0x55125). Output size is too small",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ejemplo de uso:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m _, best_model, best_config \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_model_configurations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[37], line 44\u001b[0m, in \u001b[0;36mgrid_search_model_configurations\u001b[1;34m(train, val, test, criterion, device, num_epochs)\u001b[0m\n\u001b[0;32m     41\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Sch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Lr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_opt_sched_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig: Optimizer=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Scheduler=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, LR=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Guardar el mejor modelo según la precisión y la pérdida en el conjunto de prueba\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[35], line 18\u001b[0m, in \u001b[0;36mtrain_model_opt_sched_lr\u001b[1;34m(model, criterion, optimizer, epochs, train_loader, val_loader, device, model_name)\u001b[0m\n\u001b[0;32m     16\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[33], line 52\u001b[0m, in \u001b[0;36mDifferentOptCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_layers:\n\u001b[0;32m     51\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(conv_layer(x))\n\u001b[1;32m---> 52\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Aplanar la salida de las capas convolucionales antes de pasar por las densas\u001b[39;00m\n\u001b[0;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:213\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\_jit_internal.py:624\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\45235544\\.conda\\envs\\TD6\\Lib\\site-packages\\torch\\nn\\functional.py:830\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 830\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (32x1x110250). Calculated output size: (32x0x55125). Output size is too small"
          ]
        }
      ],
      "source": [
        "# Ejemplo de uso:\n",
        "_, best_model, best_config = grid_search_model_configurations(train_loader, val_loader, test_loader, criterion, device, num_epochs=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "TD6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
